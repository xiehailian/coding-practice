## Designing Instagram

### 1. Instagram 是什么？

Instagram 是网络社交应用。在Instagram上，用户可以上传并分享他们的照片和视频。Instagram用户可以选择公开或私下分享信息。任何公开分享的内容都可以被其他用户看到，而私密的分享的信息只能被由用户指定的一些人员访问。Instagram还能让用户讲信息分享到其他社交平台，如Facebook、Twitter、Flicker和Tumblr。

### 2. 需求分析

#### 功能性需求

1. 用户可以上传/下载/浏览照片
2. 用户可以根据照片/视频的标题进行搜索
3. 用户可以关注其他用户
4. 系统应该能够生成和显示用户的信息流，其中包含所有你关注用户最近的上传的照片

#### 非功能性需求

1. 我们的服务需要高可用
2. 系统可接受的延迟为200ms，用于生成信息流
3. 一致性可能会受影响（为了满足可用性）。如果有暂时没有看到照片，这是正常的现象。
4. 系统必须高可用，任何上传的照片或视频都不应该丢失

### 3. 设计考虑

该系统包含大量的读操作，因此我们将重点构建一个可以快速检索照片的系统。

1. 实际上，用户可以上传任意多的照片。在设计系统时，有效的存储管理应该时一个关键因素
2. 在浏览照片时，低延迟应满足预期
3. 数据应该是100%可靠的，如果用户上传照片，系统将保证照片不会丢失

### 4. 存储估算

* 假设我们总共有5亿用户，其中每日活跃用户100万

* 每天200万新照片，每秒23张新照片

* 平均每张照片的占用的空间大于等于200KB

* 一天的照片需要的总容量：
  $$
  2M *200KB \geq 400GB
  $$

* 10年需要的总容量：
  $$
  400GB * 365 * 10 \approx 1425TB
  $$

### 5. 顶层设计

我们需要支持两个场景，一个是上传照片，另一个是浏览/搜索照片。我们的服务需要一些对象存储服务器来存储照片，还需要一些数据库服务器来存储照片的元数据。

![image-20191105100051726](C:\Users\xiehailian\OneDrive\xiehailian\coding-practice\go\design\instagram\image-20191105100051726.png)

### 6. 数据库模式

> 在早期阶段定义好数据库模式有助于理解不同组件之间的数据流，之后将指导数据分区

我们需要存储的数据包括：用户信息，他们上传的图片，以及他们关注的用户。Photo表将存储和照片有关的所有数据。我们需要创建索引（PhotoID, CreationDate），因为我们需要取回最近的照片。

![image-20191105101647374](C:\Users\xiehailian\OneDrive\xiehailian\coding-practice\go\design\instagram\image-20191105101647374.png)

存储上述模式的直接方法是使用像MySQL这样的RDBMS，因为我们需要联表查询。但是关系型数据库也面临挑战，尤其是当我们需要扩展它们的时候。

我们可以把照片存储在分布式的文件系统HDFS或者S3。

我们可以将上述模式储存在分布式键值数据库中，可以享受NoSQL带来的好处。所有与照片相关的元数据都可以放到一个表中，其中key是PhotoID，value是一个包含PhotoLocation、UserLocation、CreationTimestamp等的对象。

我们需要存储用户和照片之间的关系，以了解谁拥有哪些照片。我们还需要存储用户关注的人员列表。对于这两张表，我们可以使用类似Cassandra的宽列数据库。对于UserPhoto表，key将是UserID，value将是用户拥有的PhotoID的列表，存储在不同的列中。UserFollow表也可以使用类似的方案。

通常Cassandra或者键值数据库总是维护一定数量的副本保证可靠性。而且，在这样的存储中，删除操作不会立即生效，从系统永久删除之前，数据会保留几天（为了支持数据的复原）

### 7. 数据大小估计

让我们来估算下有多少数据会写入各张表中，如果需要存储10年的数据需要多少空间。

* User：假设每种int和dateTime类型是4B，那么User表中每行数据将是68B
  $$
  UserID(4 bytes) + Name(20 bytes) + Email(32 bytes) + DateOfBirth(4 bytes) + CreationDate(4 bytes) + LastLogin(4 bytes) = 68 bytes
  $$
  如果有5亿用户，那么总容量为32GB
  $$
  500000000 * 68B \approx 32GB
  $$
  
* Photo：每行数据在Photo表为284B
  $$
  PhotoID(4 bytes) + UserID(4 bytes) + PhotoPath(256 bytes) + PhotoLatitude(4 bytes) + PhotoLongitude(4 bytes) + UserLatitude(4 bytes) + UserLongitude(4 bytes) + CreationDate(4 bytes) = 284 bytes
  $$
  如果每天新照片上传数为2百万，那么每天0.5GB的空间存储
  $$
  20000000 * 284 bytes \approx 0.5GB
  $$
  10年就需要1.88TB的存储空间

* UserFollow：UserFollow表中的数据每行8B。如果我们有5亿用户并且平均每个用户关注500个用户。我们需要1.82TB的空间存储UserFollow表
  $$
  500000000 * 500 * 8 bytes \approx 1.82TB
  $$
  10年所有表需要的总空间为3.7TB
  $$
  32GB + 1.88TB + 1.82TB \approx 3.7TB
  $$

### 8. 组件设计

照片的上传（或写入）可能会很慢，因为它们必须到磁盘，而读将会更快，特别是从缓存读取。

上传的用户可能消耗掉所有可用的连接，因为上传是一个缓慢的过程。这意味着如果系统因为所有的写请求而变得繁忙，那么将无法提供读得服务。在设计系统之前，我们应该记住web服务器有连接限制。如果我们建设web服务器在任何时候最多可以有500个连接，那们它就不能有超过500个并发上传或读取。为了处理这个瓶颈，我们将读写分离。我们将有专门得都读服务器和专门的写服务器，以确保上传不会占用系统。

照片的读写分离将允许我们独立的扩展和优化这些操作。

![image-20191105151345367](C:\Users\xiehailian\OneDrive\xiehailian\coding-practice\go\design\instagram\image-20191105151345367.png)

### 9. 可靠性和冗余性

我们的服务绝不能丢失文件。因此，我们将存储每个文件的多个副本。如果一个存储服务器宕机，我们可以从另一个存储服务器上的副本中检索照片。

同样的原理也适用于系统的其他组件。如果想要系统的高可用性，我们需要在系统中运行多个服务副本，如果一些服务宕机，系统仍可保证可用性并继续运行。冗余消除了系统中的单点故障。

如果在任意时间点只能运行一个实例，那么我可以运行没有任何流量的冗余服务作为副本，但主服务器出现问题时，它可以在故障转移后接管控制权。

在系统中创建冗余服务可以消除单点故障，并在危机中提供所需的备份或备用功能。例如，如果在生产环境中运行两个相同服务的实例，其中一个出现故障或降级，则系统可以故障转移到正常的副本。故障转移可以自动发生，也可以手动干预。

![image-20191105154257029](C:\Users\xiehailian\OneDrive\xiehailian\coding-practice\go\design\instagram\image-20191105154257029.png)

### 10. 数据分片

我们来讨论下元数据分片的不同方案

#### 基于UserID的分区

假设基于UserID进行切分，这样就可以将一个用户的所有照片保存在同一个分片上。如果一个分片的1TB，那需要四个分片来存储3.7TB的数据。假设为了活得更好的性能和可伸缩性，我们我保留了10个分片。

因此，可以通过UserID % 10 来查找分片好，然后将数据存储在那里。为了在系统中唯一地标识任何照片，可以在每个PhotoID中附加分片号。

**如何生成照片的PhotoID？**每个数据库分片可以有自己的自动递增的PhotoID，因为为每个PhotoID都追加了ShardID，它在整个系统中是唯一ID。

**这种分片划分的方式有什么问题？**

1. 我们将如何处理热点用户？一些人关注了这些热门用户，很多人都会看到他们上传的照片
2. 与其他用户相比一些用户会有大量的照片，从而使存储分布不均匀
3. 如果我们不能将一个用户的所有图片存储在一个分片上怎么半？如果将用户的照片分发到多个分片上，会导致更高的延迟吗？
4. 将用户的所有照片存储在一个分片上可能导致一些问题，比如分片关闭时，用户的所有数据都不可用，或者当分片高负载时，会导致更高的延迟等等

#### 基于PhotoID的分区

如果先生成唯一的PhotoID，然后通过PhotoID % 10得到分片号，那么上述问题就解决了。这种情况下，我们不需要在PhotoID中附加ShardID，因为PhotoID本身在整个系统中是唯一的。

如何生成照片的PhotoID？在这里，我们不能用在每个分片中都有的自增序列来定义PhotoID，因为我们需要首先知道PhotoID才能找到存储它分片。一种解决方案是使用一个单独的数据库实例来生成自动递增的id。如果PhotoID可以容纳64位，那么我们可以定义一个包含64位ID字段的表。每当我们想要在系统中添加照片时，我们可以在这个表格中插入一个新行并将这个ID作为新照片的PhotoID。

这个生成键的DB不会有单点故障吗？会的。解决方法时定义两个这样的数据库，一个生成偶数编号的id，另一个生成奇数编号的id。对于MySQL，下面的脚本可以定义这样的序列：

```bash
KeyGeneratingServer1:
auto-increment-increment = 2
auto-increment-offset = 1

KeyGeneratingServer2:
auto-increment-increment = 2
auto-increment-offset = 2
```

我们可以在这个两个数据库前面放置一个负载均衡器，以便在它们之间进行轮询并处理停机事件。这两个服务器可能不同步，其中一个产生的ID比另一个多，但这不会影响我们的系统。我们可以通过位用户、照片评论等对象定义单独的ID表来扩展这种设计

我们如何规划系统未来的发展？我们可以有大量的逻辑分区来适应未来数据的增长，例如在开始时多个逻辑分区驻留在一个物理数据库服务器上。由于每个数据库服务器上可以有多个数据库实例，我们可以为任何服务器上的每个逻辑分区使用单独的数据库。因此，每当我们觉得某个数据库服务器有大量数据时，就可以将一些逻辑分区迁移至另一个服务器。我们可以维护一个配置文件或单独的数据库，它可以将我们的逻辑分区映射到数据库服务器。这将使我们能够轻松地移动分区。每当我们想要移动一个分区时，只需要更新配置文件来宣布更改。

### 11. 排序和信息流生成

要为任何指定用户创建信息流，我们需要获取用户所关注的人的最新、最流行的相关照片。

为了简单起见，我们假设要为用户的信息流获取钱100张照片。应用服务器首先将获取用户关注的人员列表。然后获取每个用户最新的100张照片的元数据信息。最后，服务器将所有这些照片提交给排名算法，它将确定前100名的照片，并将它们返回给用户。这种方法可能存在的问题时延迟更高，因为必须查询多个表并堆结果进行排序/合并/排序。为了提高效率，我们可以预先生成号信息流并存储在单独的表中。

预先生成信息流。可以使用专门的服务不断地生成用户的信息流，并将它们存储在UserNewsFeed表中。每当任何用户的信息流需要最新的照片时，我们只需要简单的查询这张表就能把结果返回给用户。每当这些服务需要生成用户的信息流时，将首先查询UserNewsFeed表，查找为该用户生成信息流的最后一次时间，然后从那时起将生成新的信息流（按照上面提到的步骤）。

向用户发送信息流有哪些不同的方法？

1. Pull：客户端可以定期从服务器上请求信息流，也可以手动请求。这种方法存在的问题是：
   * 向客户端发出pull request之前，新数据可能不会显示给用户
   * 大多数时候，如果没有新数据，pull request会导致一个空的response

2. Push：服务器可以在新数据可用时将其推送给用户。为了有效地管理这一点，用户必须与服务器保持一个长轮询请求来接受更新。这种方法地一个可能地问题是，一个关注很多人地用户或者一个拥有数百万关注者地名人用户。在这种情况下，服务器必须非常频繁地推送更新
3. Hybrid：可以将拥有大量关注地所有用户转移到基于Pull的模型，并且只将数据推送给哪些拥有几百个或上千个关注的用户。另一种方法是，服务器将更新发送给所有用户的频率不超过一定的频率，让拥有大量关注/更新的用户定期获取数据

### 12. 使用分片数据创建信息流

为任何指定用户创建信息流最重要的要求之一是从用户关注的所有人那里获取最新照片。为此，我们需要一种机制来更具创建时间对照片排序。为了有效地做到这一点，我们可以将照片创建时间作为PhotoID的一部分，因为PhotoID是主键，所以可以很快找到最新的PhotaID。

我们可以使用时间戳。假设PhotoID有两部分，第一部分标识时间戳，第二部分是一个自增序列。因此我们可以用当前时间戳加上从ID生成数据库获得的ID组成新的PhotoID。根据这个PhotoID可以找出照片要存储的分片。

新的PhotaID的大小是多大呢？也就是说从今天开始的时间戳，需要多少位才能存储下接下来50年的秒数。
$$
86400 * 365 * 50 = 1600000000
$$
我们将需要31位来存储这个数字。就平均而言，预计每秒会有23张新照片，我们可以分配9位来存储自动递增序列。每一秒都能存储512张新照片。可以每秒重置一次自增序列

### 13. 缓存和负载均衡

我们的服务需要一个大规模的照片传送系统来服务全球用户。我们的服务需要使用大规模的缓存服务器和使用CDNS来向用户就近推送内容。

我们可以为元数据服务器引入缓存来缓存热点数据。我们可以使用Memcache缓存数据并且应用服务器在查询数据库前可以快速检查缓存里是否存在。LRU是一种合理的缓存清楚策略。在此策略下，我们首先要丢弃最近最少查看的数据。

如何构建更智能的缓存？如果我们用80-20法则，也就是每天20%的照片浏览量产生了80%的流量，这意味着某些照片非常受欢迎，大多数人都会去看。这意味着我们可以尝试缓存每天20%的照片和元数据。

